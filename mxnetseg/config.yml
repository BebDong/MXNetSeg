# config hyper-parameters here concerning a training trial

# [model]
# supported models (case-sensitive):
# 'DeepLabv3', 'DeepLabv3PlusX', 'DeepLabv3PlusR', 'SwiftResNet', 'SwiftResNetPr',
# 'ACFNet', 'AttentionToScale', 'AttaNet', 'BiSeNetX', 'BiSeNetR', 'DANet', 'DenseASPP',
# 'EPRNet', 'FCNResNet', 'FCNMobileNet', 'LadderDenseNet', 'PSPNet', 'SeENet',
# 'SemanticFPN', 'SETR',
# 'CANetv1', 'CANetv2'
model_name: BiSeNetR
backbone: resnet18
norm: sbn
aux: False
aux_weight: ~
lr_mult: 1
dilate: False

# [init]
# backbone_init: one of {~, cls, seg}, when set to seg, backbone_ckpt need to be specified
# resume: checkpoint of the segmentation model
backbone_init:
  manner: cls
  backbone_ckpt: ~
resume: ~

# [dataset]
# supported dataset (case-sensitive):
# 'MSCOCO','ADE20K', 'Aeroscapes', 'BDD100K', 'CamVid', 'CityCoarse', 'Cityscapes',
# 'GATECH', 'Mapillary', 'MHPV1', 'NYUv2', 'PascalContext', 'SBD', 'SiftFlow',
# 'StanfordBackground', 'SUNRGBD', 'PascalVOC', 'PascalVOCAug', 'WeizmannHorses'
data_name: Cityscapes
crop_size: 768
base_size: 2048

# [optimizer]
# supported optimizers: 'sgd', 'nag', 'adam'
# supported learning rate scheduler: 'poly', 'cosine', 'constant', 'step', 'linear'
lr: 1.e-2
target_lr: 0
wd: 1.e-4
momentum: 0.9
optimizer: sgd
lr_scheduler: poly
poly:
  power: 0.9
step:
  step_factor: 0.5
  step_epoch:
    - 5
adam:
  adam_beta1: 0.9
  adam_beta2: 0.999

# [training]
epochs: 240
bs_train: 8
bs_val: 16